{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5637b93e-6538-49f6-b56a-c8037932af8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Loading input files...\n",
      "üß† Loading SentenceTransformer model...\n",
      "‚öôÔ∏è Encoding Tools and Tech examples...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aded80bd95042e681c1176a05296bc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/651 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6acddde62c204127baced905b5f95e52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/510 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ Matching noun phrases for each resume...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [00:04<00:00, 22.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saving outputs to:\n",
      " - ../data/similarity_outputs/similarity_matrix_tools.csv\n",
      " - ../data/similarity_outputs/similarity_matrix_tech.csv\n",
      "‚úÖ Done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from textblob import TextBlob\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# -------------------------\n",
    "# Config\n",
    "# -------------------------\n",
    "DATA_DIR = \"../data/o_net_tools_tech/\"\n",
    "TOOLS_FILE = \"Tools Used.xlsx\"\n",
    "TECH_FILE = \"Technology Skills.xlsx\"\n",
    "RESUME_FILE = \"../data/annotations_scenario_1/cleaned_resumes.csv\"\n",
    "\n",
    "OUTPUT_DIR = \"../data/similarity_outputs/\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "TOOLS_OUTPUT = os.path.join(OUTPUT_DIR, \"similarity_matrix_tools.csv\")\n",
    "TECH_OUTPUT = os.path.join(OUTPUT_DIR, \"similarity_matrix_tech.csv\")\n",
    "SIMILARITY_THRESHOLD = 0.65\n",
    "\n",
    "# -------------------------\n",
    "# Load Data\n",
    "# -------------------------\n",
    "print(\"üì• Loading input files...\")\n",
    "tools_df = pd.read_excel(os.path.join(DATA_DIR, TOOLS_FILE))\n",
    "tech_df = pd.read_excel(os.path.join(DATA_DIR, TECH_FILE))\n",
    "resume_df = pd.read_csv(RESUME_FILE)\n",
    "\n",
    "# Clean and rename relevant columns\n",
    "tools_df = tools_df.rename(columns={'O*NET-SOC Code': 'onetsoc_code', 'Example': 'tool_example'})\n",
    "tech_df = tech_df.rename(columns={'O*NET-SOC Code': 'onetsoc_code', 'Example': 'tech_example'})\n",
    "tools_df = tools_df.dropna(subset=['tool_example'])\n",
    "tech_df = tech_df.dropna(subset=['tech_example'])\n",
    "\n",
    "# -------------------------\n",
    "# Load embedding model\n",
    "# -------------------------\n",
    "print(\"üß† Loading SentenceTransformer model...\")\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\", device=\"cuda\")\n",
    "\n",
    "# -------------------------\n",
    "# Embed Tools and Tech Examples\n",
    "# -------------------------\n",
    "print(\"‚öôÔ∏è Encoding Tools and Tech examples...\")\n",
    "\n",
    "tools_df['embedding'] = model.encode(\n",
    "    tools_df['tool_example'].astype(str).tolist(),\n",
    "    batch_size=64,\n",
    "    convert_to_numpy=True,\n",
    "    show_progress_bar=True\n",
    ").tolist()\n",
    "\n",
    "tech_df['embedding'] = model.encode(\n",
    "    tech_df['tech_example'].astype(str).tolist(),\n",
    "    batch_size=64,\n",
    "    convert_to_numpy=True,\n",
    "    show_progress_bar=True\n",
    ").tolist()\n",
    "\n",
    "tools_tensor = torch.nn.functional.normalize(torch.tensor(np.vstack(tools_df['embedding'].values), dtype=torch.float32).to(\"cuda\"), dim=1)\n",
    "tech_tensor = torch.nn.functional.normalize(torch.tensor(np.vstack(tech_df['embedding'].values), dtype=torch.float32).to(\"cuda\"), dim=1)\n",
    "\n",
    "# -------------------------\n",
    "# Matching function\n",
    "# -------------------------\n",
    "def match_entities(resume_id, resume_text, noun_phrases, noun_embeddings, entity_df, entity_tensor, entity_type):\n",
    "    matches = []\n",
    "    noun_tensor = torch.tensor(np.vstack(noun_embeddings), dtype=torch.float32).to(\"cuda\")\n",
    "    noun_tensor = torch.nn.functional.normalize(noun_tensor, dim=1)\n",
    "\n",
    "    sim_matrix = torch.matmul(noun_tensor, entity_tensor.T)\n",
    "    max_sim, max_idx = sim_matrix.max(dim=1)\n",
    "    mask = max_sim >= SIMILARITY_THRESHOLD\n",
    "\n",
    "    for i in torch.where(mask)[0].tolist():\n",
    "        entity_row = entity_df.iloc[max_idx[i].item()]\n",
    "        similarity = max_sim[i].item()\n",
    "        noun_phrase = noun_phrases[i]\n",
    "\n",
    "        if entity_type == \"Tool\":\n",
    "            score = 1.0\n",
    "            entity_col = \"tools_entity\"\n",
    "            example_text = entity_row['tool_example']\n",
    "        else:\n",
    "            score = 1.0 if entity_row.get(\"Hot Technology\", \"N\") == \"Y\" else 0.75\n",
    "            entity_col = \"tech_entity\"\n",
    "            example_text = entity_row['tech_example']\n",
    "\n",
    "        match = {\n",
    "            'resume_id': resume_id,\n",
    "            'resume_text': resume_text,\n",
    "            'noun_phrase': noun_phrase,\n",
    "            entity_col: entity_row['Commodity Title'],\n",
    "            'example_text': example_text,\n",
    "            'similarity_score': similarity,\n",
    "            'entity_job_title': entity_row['Title'],\n",
    "            'onetsoc_code': entity_row['onetsoc_code'],\n",
    "            'scale_id': 'N/A',\n",
    "            'data_value': score\n",
    "        }\n",
    "\n",
    "        matches.append(match)\n",
    "\n",
    "    return matches\n",
    "\n",
    "# -------------------------\n",
    "# Main Matching Loop\n",
    "# -------------------------\n",
    "print(\"üîÅ Matching noun phrases for each resume...\")\n",
    "tool_matches = []\n",
    "tech_matches = []\n",
    "\n",
    "for _, row in tqdm(resume_df.iterrows(), total=len(resume_df)):\n",
    "    resume_id = row['resume_id']\n",
    "    resume_text = row['resume_text']\n",
    "    noun_phrases = list(set(TextBlob(resume_text).noun_phrases))  # deduplicate\n",
    "\n",
    "    if not noun_phrases:\n",
    "        continue\n",
    "\n",
    "    noun_embeddings = model.encode(noun_phrases, batch_size=32, convert_to_numpy=True)\n",
    "\n",
    "    # Match to tools\n",
    "    tool_matches.extend(\n",
    "        match_entities(resume_id, resume_text, noun_phrases, noun_embeddings, tools_df, tools_tensor, \"Tool\")\n",
    "    )\n",
    "\n",
    "    # Match to tech\n",
    "    tech_matches.extend(\n",
    "        match_entities(resume_id, resume_text, noun_phrases, noun_embeddings, tech_df, tech_tensor, \"Tech\")\n",
    "    )\n",
    "\n",
    "# -------------------------\n",
    "# Save Results\n",
    "# -------------------------\n",
    "tool_columns = [\n",
    "    'resume_id', 'resume_text', 'noun_phrase', 'tools_entity', 'example_text',\n",
    "    'similarity_score', 'entity_job_title', 'onetsoc_code', 'scale_id', 'data_value'\n",
    "]\n",
    "\n",
    "tech_columns = [\n",
    "    'resume_id', 'resume_text', 'noun_phrase', 'tech_entity', 'example_text',\n",
    "    'similarity_score', 'entity_job_title', 'onetsoc_code', 'scale_id', 'data_value'\n",
    "]\n",
    "\n",
    "print(f\"üíæ Saving outputs to:\\n - {TOOLS_OUTPUT}\\n - {TECH_OUTPUT}\")\n",
    "pd.DataFrame(tool_matches)[tool_columns].to_csv(TOOLS_OUTPUT, index=False)\n",
    "pd.DataFrame(tech_matches)[tech_columns].to_csv(TECH_OUTPUT, index=False)\n",
    "print(\"‚úÖ Done.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
