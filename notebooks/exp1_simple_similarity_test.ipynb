{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a7cd866-954b-49de-8611-47ab42856cb7",
   "metadata": {},
   "source": [
    "### Similarity between O*Net Knowledge and Resumes\n",
    "\n",
    "This is a quick test to see how similarity between a whole resume and the o*net knowledge data looks like. The assumption is that measuring the entire resume embeddings to each Knowledge entity will result in a much lower score than the 65% refered in the referenced researh paper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "100af170-3a6a-45f0-94b4-50a9df46a73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   resume_id             job_title               knowledge_entity  \\\n",
      "0          4  Computer Programmers  Administration and Management   \n",
      "2          4  Computer Programmers                 Administrative   \n",
      "4          4  Computer Programmers       Economics and Accounting   \n",
      "6          4  Computer Programmers            Sales and Marketing   \n",
      "8          4  Computer Programmers  Customer and Personal Service   \n",
      "\n",
      "   similarity_score  \n",
      "0          0.309047  \n",
      "2          0.231593  \n",
      "4          0.223551  \n",
      "6          0.269907  \n",
      "8          0.232240  \n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the embedding model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(\"../data/annotations_scenario_1/annotations_scenario_1.db\")\n",
    "\n",
    "# Step 1: Query 10 resumes with rating = 5\n",
    "query_resumes = \"\"\"\n",
    "SELECT r.id AS resume_id, r.resume_text, pj.job_title\n",
    "FROM resumes r\n",
    "JOIN annotations a ON r.id = a.resume_id\n",
    "JOIN predicted_jobs pj ON r.id = pj.resume_id\n",
    "WHERE a.rating = 5\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "df_resumes = pd.read_sql_query(query_resumes, conn)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "# Step 2: Load the O*NET knowledge dataset (previously processed)\n",
    "df_onet = pd.read_csv(\"../data/annotations_scenario_1/processed_onet_knowledge.csv\")\n",
    "\n",
    "# Step 3: Initialize an empty list to store similarity results\n",
    "similarity_results = []\n",
    "\n",
    "# Step 4: Compute similarity for each resume and its corresponding job knowledge entities\n",
    "for _, row in df_resumes.iterrows():\n",
    "    resume_id = row[\"resume_id\"]\n",
    "    resume_text = row[\"resume_text\"]\n",
    "    job_title = row[\"job_title\"]\n",
    "\n",
    "    # Get knowledge entities for this job title\n",
    "    df_knowledge = df_onet[df_onet[\"job_title\"] == job_title]\n",
    "\n",
    "    if df_knowledge.empty:\n",
    "        print(f\"‚ö†Ô∏è No knowledge entities found for job: {job_title} (Resume ID: {resume_id})\")\n",
    "        continue  # Skip if no knowledge data exists for this job\n",
    "\n",
    "    # Generate embeddings\n",
    "    resume_embedding = model.encode(resume_text, convert_to_numpy=True)\n",
    "    knowledge_embeddings = df_knowledge[\"knowledge_entity\"].apply(lambda x: model.encode(x, convert_to_numpy=True))\n",
    "\n",
    "    # Compute similarity\n",
    "    similarity_scores = cosine_similarity([resume_embedding], list(knowledge_embeddings))\n",
    "\n",
    "    # Store results\n",
    "    for knowledge_entity, score in zip(df_knowledge[\"knowledge_entity\"], similarity_scores[0]):\n",
    "        similarity_results.append({\"resume_id\": resume_id, \"job_title\": job_title, \"knowledge_entity\": knowledge_entity, \"similarity_score\": score})\n",
    "\n",
    "# Convert results to DataFrame\n",
    "df_similarity = pd.DataFrame(similarity_results)\n",
    "\n",
    "# Remove duplicates if any remain\n",
    "df_similarity.drop_duplicates(inplace=True)\n",
    "\n",
    "# Print a preview of the similarity matrix\n",
    "print(df_similarity.head())\n",
    "\n",
    "# # Save to CSV for further analysis\n",
    "# df_similarity.to_csv(\"../data/annotations_scenario_1/resume_knowledge_similarity_matrix.csv\", index=False)\n",
    "\n",
    "# print(\"‚úÖ Similarity matrix saved as 'resume_knowledge_similarity_matrix.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8722056-e108-496c-8692-e41161f16cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Highest Similarity Score:\n",
      "     resume_id                                     job_title  \\\n",
      "346          5                   Computer Network Architects   \n",
      "412          5                          Computer Programmers   \n",
      "478          5         Computer Systems Engineers/Architects   \n",
      "544          5  Computer and Information Research Scientists   \n",
      "610          5                            Robotics Engineers   \n",
      "\n",
      "              knowledge_entity  similarity_score  \n",
      "346  Computers and Electronics          0.418219  \n",
      "412  Computers and Electronics          0.418219  \n",
      "478  Computers and Electronics          0.418219  \n",
      "544  Computers and Electronics          0.418219  \n",
      "610  Computers and Electronics          0.418219  \n"
     ]
    }
   ],
   "source": [
    "# Print the highest similarity score\n",
    "max_similarity = df_similarity[\"similarity_score\"].max()\n",
    "highest_match = df_similarity[df_similarity[\"similarity_score\"] == max_similarity]\n",
    "\n",
    "print(\"\\nüéØ Highest Similarity Score:\")\n",
    "print(highest_match)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae2a069-d04f-4e7e-a72e-142de71a4234",
   "metadata": {},
   "source": [
    "### Analysis:\n",
    "\n",
    "As anticipated, even the best score is less than the 65% threshold"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
