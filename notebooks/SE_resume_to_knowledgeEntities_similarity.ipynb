{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa03d54d-1321-4350-ba36-410cec567dc8",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Resume-to-O*NET Knowledge Mapping (High-Quality Annotations)\n",
    "\n",
    "### Purpose\n",
    "This notebook demonstrates a focused exploration of how high-quality resumes align with the **O*NET Knowledge taxonomy** using semantic similarity techniques.\n",
    "\n",
    "> âœ… This exploration is based on:\n",
    "> - **Objective 1**\n",
    "> - **Annotations Set 1**\n",
    "> - Resumes with a **rating score of 5**\n",
    "\n",
    "The goal is to:\n",
    "- Extract meaningful **noun phrases** from resume text\n",
    "- Match them semantically to relevant **O*NET knowledge entities**\n",
    "- Assess the **semantic similarity** between the resume content and standardized knowledge requirements\n",
    "- Compare against the **importance (`data_value`)** of those knowledge areas for a given job role\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Methodology\n",
    "\n",
    "1. **Data Selection**  \n",
    "   - Resumes are queried from a SQLite database where the annotation rating is 5.\n",
    "   - Each resume is associated with a predicted job title.\n",
    "\n",
    "2. **Text Processing**  \n",
    "   - `TextBlob` is used to extract **noun phrases** from each resume, replicating the method described in the referenced research.\n",
    "\n",
    "3. **Knowledge Entity Matching**  \n",
    "   - For each resume, we select the corresponding **O*NET knowledge entities** by fuzzy-matching the job title to the `job_title` column in the O*NET knowledge dataset.\n",
    "\n",
    "4. **Embedding & Similarity Scoring**  \n",
    "   - Both noun phrases and knowledge entities are encoded using the `all-MiniLM-L6-v2` **SentenceTransformer**.\n",
    "   - **Cosine similarity** is calculated between each noun phrase and each knowledge entity.\n",
    "   - All matches with **similarity â‰¥ 0.65** are retained.\n",
    "\n",
    "5. **Output Construction**  \n",
    "   - For each `(noun phrase, knowledge entity)` pair, the following are recorded:\n",
    "     - Resume ID\n",
    "     - Job Title\n",
    "     - Noun Phrase\n",
    "     - O*NET Knowledge Entity\n",
    "     - Cosine Similarity Score\n",
    "     - O*NET `data_value` (importance level of the knowledge for that job)\n",
    "\n",
    "---\n",
    "\n",
    "### Outcome\n",
    "The output DataFrame provides an interpretable mapping between **resume content and job-specific knowledge requirements**. It enables:\n",
    "- Visualizing **how well a resume covers the most important knowledge areas** for a job\n",
    "- Exploring **semantic overlap** between applicant experience and formal occupation standards\n",
    "- Evaluating entity alignment at a **granular, phrase-level resolution**\n",
    "\n",
    "This exploration supports downstream use cases like:\n",
    "- Automated resume-job fit scoring\n",
    "- Gap analysis between candidate skills and job requirements\n",
    "- Training data analysis for classification models\n",
    "\n",
    "---\n",
    "\n",
    "### References\n",
    "Alonso, R., DessÃ­, D., Meloni, A., & Reforgiato Recupero, D. (2025).  \n",
    "**A novel approach for job matching and skill recommendation using transformers and the O\\*NET database**.  \n",
    "*Big Data Research, 39*, 100509. [DOI: 10.1016/j.bdr.2024.100509](https://doi.org/10.1016/j.bdr.2024.100509)\n",
    "\n",
    "This notebook replicates and adapts core techniques from the above paper, including noun phrase extraction with TextBlob and semantic similarity scoring against O\\*NET entities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3dc6522-98d2-436c-8a49-2a985826daa3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# or \"cuda:1\" for the second GPU\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Load the model\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSentenceTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mall-MiniLM-L6-v2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Connect to the SQLite database\u001b[39;00m\n\u001b[1;32m     19\u001b[0m db_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/annotations_scenario_1/annotations_scenario_1.db\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:221\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[0;34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, cache_folder, trust_remote_code, revision, token, use_auth_token, truncate_dim)\u001b[0m\n\u001b[1;32m    218\u001b[0m     device \u001b[38;5;241m=\u001b[39m get_device_name()\n\u001b[1;32m    219\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse pytorch device_name: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(device))\n\u001b[0;32m--> 221\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_hpu_graph_enabled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_prompt_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_prompt_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompts:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1174\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1172\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 780 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:805\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 805\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    808\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1160\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1154\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1155\u001b[0m             device,\n\u001b[1;32m   1156\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m             non_blocking,\n\u001b[1;32m   1158\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1159\u001b[0m         )\n\u001b[0;32m-> 1160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/cuda/__init__.py:305\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    303\u001b[0m     )\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    309\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Load the embedding model\n",
    "import torch\n",
    "\n",
    "# Set the target GPU (e.g., GPU 0 or GPU 1)\n",
    "device = torch.device(\"cuda:0\")  # or \"cuda:1\" for the second GPU\n",
    "\n",
    "# Load the model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\", device=device)\n",
    "\n",
    "\n",
    "# Connect to the SQLite database\n",
    "db_path = \"../data/annotations_scenario_1/annotations_scenario_1.db\"\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# Step 1: Query 10 resumes with rating = 5\n",
    "query_resumes = \"\"\"\n",
    "SELECT r.id AS resume_id, r.resume_text, pj.job_title\n",
    "FROM resumes r\n",
    "JOIN annotations a ON r.id = a.resume_id\n",
    "JOIN predicted_jobs pj ON r.id = pj.resume_id\n",
    "WHERE a.rating = 5\n",
    "\"\"\"\n",
    "df_resumes = pd.read_sql_query(query_resumes, conn)\n",
    "conn.close()\n",
    "\n",
    "# Step 2: Load the O*NET knowledge dataset (previously processed)\n",
    "df_onet = pd.read_csv(\"../data/annotations_scenario_1/processed_onet_knowledge.csv\")\n",
    "\n",
    "# Step 3: Initialize a list to collect similarity results\n",
    "similarity_results = []\n",
    "\n",
    "# Step 4: Iterate over resumes\n",
    "for _, row in df_resumes.iterrows():\n",
    "    resume_id = row[\"resume_id\"]\n",
    "    resume_text = row[\"resume_text\"]\n",
    "    job_title = row[\"job_title\"]\n",
    "\n",
    "    # Get knowledge entities for this job title using pattern matching\n",
    "    df_knowledge = df_onet[df_onet[\"job_title\"].str.contains(job_title, case=False, na=False, regex=True)]\n",
    "\n",
    "    if df_knowledge.empty:\n",
    "        print(f\"âš ï¸ No knowledge entities found for job: {job_title} (Resume ID: {resume_id})\")\n",
    "        continue\n",
    "\n",
    "    # Extract noun phrases from the resume\n",
    "    blob = TextBlob(resume_text)\n",
    "    noun_phrases = list(set(blob.noun_phrases))  # Remove duplicates\n",
    "\n",
    "    if not noun_phrases:\n",
    "        print(f\"âš ï¸ No noun phrases found in resume ID {resume_id}\")\n",
    "        continue\n",
    "\n",
    "    # Encode noun phrases and knowledge entities\n",
    "    resume_embeddings = model.encode(noun_phrases, convert_to_numpy=True)\n",
    "    knowledge_entities = df_knowledge[\"knowledge_entity\"].tolist()\n",
    "    knowledge_embeddings = model.encode(knowledge_entities, convert_to_numpy=True)\n",
    "\n",
    "    # Compute pairwise cosine similarity\n",
    "    similarity_matrix = cosine_similarity(resume_embeddings, knowledge_embeddings)\n",
    "\n",
    "    # Store all similarity scores â‰¥ 0.65, and include data_value from df_knowledge\n",
    "    threshold = 0.65\n",
    "    for i, noun_phrase in enumerate(noun_phrases):\n",
    "        for j, knowledge_entity in enumerate(knowledge_entities):\n",
    "            score = similarity_matrix[i, j]\n",
    "            if score >= threshold:\n",
    "                data_value = df_knowledge.iloc[j][\"data_value\"]\n",
    "                similarity_results.append({\n",
    "                    \"resume_id\": resume_id,\n",
    "                    \"job_title\": job_title,\n",
    "                    \"noun_phrase\": noun_phrase,\n",
    "                    \"knowledge_entity\": knowledge_entity,\n",
    "                    \"similarity_score\": score,\n",
    "                    \"data_value\": data_value\n",
    "                })\n",
    "\n",
    "\n",
    "\n",
    "# Convert results to DataFrame\n",
    "df_similarity = pd.DataFrame(similarity_results).drop_duplicates()\n",
    "\n",
    "# Display the similarity results\n",
    "print(df_similarity.head())\n",
    "\n",
    "# (Optional) Save to CSV\n",
    "# df_similarity.to_csv(\"resume_knowledge_similarity_matrix.csv\", index=False)\n",
    "\n",
    "print(\"âœ… Done computing similarity based on noun phrases.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ca5837-c5e0-469e-b304-13c35d447d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_similarity[\"resume_id\"].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab6405f-85c1-466e-800f-f43be8a909ba",
   "metadata": {},
   "source": [
    "# Lets connect to neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8fc58c-b5c2-49fa-98c8-8c161ce1b380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0100c7c5-eaaf-46ae-abc2-e9de4b65a5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "# Replace with your Neo4j URI and credentials\n",
    "NEO4J_URI = \"bolt://20.14.162.151:7687\" \n",
    "NEO4J_USER = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"recluse2025\"\n",
    "\n",
    "# Connect to Neo4j\n",
    "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "\n",
    "# Transaction function to push nodes and relationships\n",
    "def push_to_neo4j(tx, record):\n",
    "    tx.run(\"\"\"\n",
    "        MERGE (r:Resume {id: $resume_id})\n",
    "        SET r.job_title = $job_title\n",
    "\n",
    "        MERGE (n:NounPhrase {text: $noun_phrase})\n",
    "        MERGE (k:Knowledge {entity: $knowledge_entity})\n",
    "        MERGE (j:JobTitle {title: $job_title})\n",
    "\n",
    "        MERGE (r)-[:CONTAINS]->(n)\n",
    "        MERGE (n)-[s:SIMILAR_TO]->(k)\n",
    "        SET s.score = $similarity_score\n",
    "\n",
    "        MERGE (k)-[rj:REQUIRED_FOR]->(j)\n",
    "        SET rj.importance = $data_value\n",
    "    \"\"\", \n",
    "    resume_id=record[\"resume_id\"],\n",
    "    job_title=record[\"job_title\"],\n",
    "    noun_phrase=record[\"noun_phrase\"],\n",
    "    knowledge_entity=record[\"knowledge_entity\"],\n",
    "    similarity_score=round(record[\"similarity_score\"], 4),\n",
    "    data_value=record[\"data_value\"])\n",
    "\n",
    "\n",
    "# Push rows from DataFrame to Neo4j\n",
    "with driver.session() as session:\n",
    "    for _, row in df_similarity.iterrows():\n",
    "        session.execute_write(push_to_neo4j, row)\n",
    "\n",
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
