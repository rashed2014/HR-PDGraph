{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc3a5854-f59c-4878-abcd-2e25b5398f92",
   "metadata": {},
   "source": [
    "### O Net database set up\n",
    "\n",
    "Setting up the database to easily query the O Net datasets\n",
    "\n",
    "1. Download mysql script from O Net: https://www.onetcenter.org/database.html#all-files\n",
    "2. Convert mysql .sql scripts to a combined sqlite script\n",
    "3. Create database either pythonically or using command prmpt as below\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc831ff3-9dd4-4eaa-93ed-0931a7cd29f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening 41 files\n",
      "Converted 36_skills_to_work_context.sql to SQLite-compatible format.\n",
      "Converted 24_dwa_reference.sql to SQLite-compatible format.\n",
      "Converted 31_technology_skills.sql to SQLite-compatible format.\n",
      "Converted 23_iwa_reference.sql to SQLite-compatible format.\n",
      "Converted 28_unspsc_reference.sql to SQLite-compatible format.\n",
      "Converted 17_task_statements.sql to SQLite-compatible format.\n",
      "Converted 38_basic_interests_to_riasec.sql to SQLite-compatible format.\n",
      "Converted 16_skills.sql to SQLite-compatible format.\n",
      "Converted 13_interests.sql to SQLite-compatible format.\n",
      "Converted 33_abilities_to_work_activities.sql to SQLite-compatible format.\n",
      "Converted 14_job_zones.sql to SQLite-compatible format.\n",
      "Converted 39_interests_illus_activities.sql to SQLite-compatible format.\n",
      "Converted 06_level_scale_anchors.sql to SQLite-compatible format.\n",
      "Converted 27_related_occupations.sql to SQLite-compatible format.\n",
      "Converted 02_job_zone_reference.sql to SQLite-compatible format.\n",
      "Converted 40_interests_illus_occupations.sql to SQLite-compatible format.\n",
      "Converted 03_occupation_data.sql to SQLite-compatible format.\n",
      "Converted 25_tasks_to_dwas.sql to SQLite-compatible format.\n",
      "Converted 26_emerging_tasks.sql to SQLite-compatible format.\n",
      "Converted 19_work_activities.sql to SQLite-compatible format.\n",
      "Converted 01_content_model_reference.sql to SQLite-compatible format.\n",
      "Converted 18_task_ratings.sql to SQLite-compatible format.\n",
      "Converted 30_sample_of_reported_titles.sql to SQLite-compatible format.\n",
      "Converted 37_riasec_keywords.sql to SQLite-compatible format.\n",
      "Converted 12_education_training_experience.sql to SQLite-compatible format.\n",
      "Converted 08_survey_booklet_locations.sql to SQLite-compatible format.\n",
      "Converted 32_tools_used.sql to SQLite-compatible format.\n",
      "Converted 29_alternate_titles.sql to SQLite-compatible format.\n",
      "Converted 21_work_styles.sql to SQLite-compatible format.\n",
      "Converted 11_abilities.sql to SQLite-compatible format.\n",
      "Converted 04_scales_reference.sql to SQLite-compatible format.\n",
      "Converted 34_abilities_to_work_context.sql to SQLite-compatible format.\n",
      "Converted 22_work_values.sql to SQLite-compatible format.\n",
      "Converted 15_knowledge.sql to SQLite-compatible format.\n",
      "Converted 07_occupation_level_metadata.sql to SQLite-compatible format.\n",
      "Converted 10_work_context_categories.sql to SQLite-compatible format.\n",
      "Converted 05_ete_categories.sql to SQLite-compatible format.\n",
      "Converted 35_skills_to_work_activities.sql to SQLite-compatible format.\n",
      "Converted 09_task_categories.sql to SQLite-compatible format.\n",
      "Converted 20_work_context.sql to SQLite-compatible format.\n",
      "Converted SQL files saved to data/O_Net_SqlLite/o_net_sqlite_schema.sql\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "def convert_mysql_to_sqlite(mysql_files_dir, sqlite_file_path):\n",
    "    # Create or open the SQLite database\n",
    "    with open(sqlite_file_path, 'w') as sqlite_file:\n",
    "        print(f\"opening {len(os.listdir(mysql_files_dir))} files\")\n",
    "        # Loop through each .sql file in the directory\n",
    "        for filename in os.listdir(mysql_files_dir):\n",
    "            if filename.endswith(\".sql\"):\n",
    "                # Full path to the MySQL .sql file\n",
    "                mysql_file_path = os.path.join(mysql_files_dir, filename)\n",
    "\n",
    "                # Read the content of the MySQL SQL file\n",
    "                with open(mysql_file_path, 'r') as mysql_file:\n",
    "                    sql_content = mysql_file.read()\n",
    "\n",
    "                    # Make necessary replacements to convert MySQL to SQLite syntax\n",
    "                    sql_content = re.sub(r'AUTO_INCREMENT', 'INTEGER PRIMARY KEY AUTOINCREMENT', sql_content)\n",
    "                    sql_content = re.sub(r'\\bINT\\(\\d+\\)\\b', 'INTEGER', sql_content)\n",
    "                    sql_content = re.sub(r'\\bVARCHAR\\(\\d+\\)\\b', 'TEXT', sql_content)\n",
    "                    sql_content = re.sub(r'\\bDATETIME\\b', 'TEXT', sql_content)\n",
    "                    sql_content = re.sub(r'\\bTIMESTAMP\\b', 'TEXT', sql_content)\n",
    "                    sql_content = re.sub(r'`', '', sql_content)  # Remove backticks for SQLite\n",
    "\n",
    "                    # Remove MySQL-specific settings (like ENGINE and CHARSET)\n",
    "                    sql_content = re.sub(r'ENGINE=\\w+', '', sql_content)\n",
    "                    sql_content = re.sub(r'CHARSET=\\w+', '', sql_content)\n",
    "\n",
    "                    # Write the converted content into the SQLite .sql file\n",
    "                    sqlite_file.write(sql_content + \"\\n\\n\")\n",
    "\n",
    "                print(f\"Converted {filename} to SQLite-compatible format.\")\n",
    "\n",
    "    print(f\"Converted SQL files saved to {sqlite_file_path}\")\n",
    "\n",
    "# Example usage:\n",
    "mysql_files_directory = '../data/O_Net_MySQL/db_29_2_mysql/'  # Folder containing MySQL .sql files\n",
    "sqlite_output_file = '../data/O_Net_SqlLite/o_net_sqlite_schema.sql'  # SQLite-compatible .sql file\n",
    "\n",
    "# Convert the MySQL .sql files to a single SQLite .sql file\n",
    "convert_mysql_to_sqlite(mysql_files_directory, sqlite_output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f109b4d-90d8-437d-9115-8c6037685c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sqlite3\n",
    "\n",
    "# def create_database_from_sqlite_sql(sqlite_file, sql_file):\n",
    "#     # Connect to SQLite database (creates the database file if it doesn't exist)\n",
    "#     conn = sqlite3.connect(sqlite_file)\n",
    "#     cursor = conn.cursor()\n",
    "\n",
    "#     # Open and read the converted SQL file\n",
    "#     with open(sql_file, 'r') as file:\n",
    "#         sql_content = file.read()\n",
    "\n",
    "#     # Execute the SQL commands to create the tables and insert data\n",
    "#     cursor.executescript(sql_content)\n",
    "\n",
    "#     # Commit and close the connection\n",
    "#     conn.commit()\n",
    "#     conn.close()\n",
    "#     print(f\"Database {sqlite_file} created and data imported successfully!\")\n",
    "\n",
    "# # Example usage:\n",
    "# sqlite_file = '../data/O_Net_SqlLite/onet_database.db'  # SQLite database file\n",
    "# sql_file = '../data/O_Net_SqlLite/o_net_sqlite_schema.sql'  # Converted SQL file\n",
    "\n",
    "# create_database_from_sqlite_sql(sqlite_file, sql_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2646a2e8-2de1-4277-9520-b1633004867e",
   "metadata": {},
   "source": [
    "### Alternate option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e042238-8959-48ba-a3b4-3d0dcaabfc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sqlite3 path/to/your/onet_database.db\n",
    "!.read path/to/your/o_net_sqlite_schema.sql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcad36e6-3eec-4f9e-abb3-8402ad8ee49e",
   "metadata": {},
   "source": [
    "### Annotations Tables\n",
    "\n",
    "Following the research work \"A novel approach for job matching and skill recommendation using transformers and the O*NET database\", we are creating tables for the annotations in the o_net database.\n",
    "\n",
    "Paper: https://www.sciencedirect.com/science/article/pii/S2214579625000048\n",
    "Github: https://gitlab.com/hri_lab1/using-transformers-and-o-net-to-match-jobs-to-applicants-resumes\n",
    "\n",
    "1. Create tables\n",
    "2. Insert data from the json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aeb1f9b0-b8a0-4386-ba94-a95400143e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sqlite3 ../data/annotations_scenario_1/annotations_scenario_1.db < d../ata/annotations_scenario_1/annotations_scenario_1.sql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dfba6d2-9220-477e-a027-5b22146ad0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Found 3 JSON files. Processing...\n",
      "âœ… Processed: naive_alg2_results - annotator_1.json\n",
      "âœ… Processed: naive_alg2_results - annotator_3.json\n",
      "âœ… Processed: naive_alg2_results - annotator_2.json\n",
      "ðŸŽ‰ Scenario 1 data inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import json\n",
    "import os\n",
    "\n",
    "# SQLite database file\n",
    "db_file = \"../data/annotations_scenario_1/annotations_scenario_1.db\"\n",
    "conn = sqlite3.connect(db_file)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Directory containing JSON files for Scenario 1\n",
    "scenario_1_dir = \"../data/annotations_scenario_1\"\n",
    "\n",
    "# Function to insert JSON data\n",
    "def insert_annotations(json_file):\n",
    "    try:\n",
    "        with open(json_file, \"r\", encoding=\"utf-8\") as file:\n",
    "            resume_data = json.load(file)\n",
    "\n",
    "        for resume in resume_data:\n",
    "            # Insert into resumes table\n",
    "            cursor.execute(\n",
    "                \"INSERT INTO resumes (resume_text, original_job) VALUES (?, ?)\",\n",
    "                (resume.get(\"resume_text\", \"\"), resume.get(\"original_job\", \"Unknown\")),\n",
    "            )\n",
    "            resume_id = cursor.lastrowid  # Get the inserted resume ID\n",
    "\n",
    "            # Insert predicted jobs (from the research model)\n",
    "            for job in resume.get(\"predicted_jobs\", []):\n",
    "                cursor.execute(\n",
    "                    \"INSERT INTO predicted_jobs (resume_id, job_code, job_title) VALUES (?, ?, ?)\",\n",
    "                    (resume_id, job[0], job[1]),\n",
    "                )\n",
    "\n",
    "            # Insert annotations (human expert ratings) safely\n",
    "            for annotator_id, key in enumerate([\"annotation_1\", \"annotation_2\", \"annotation_3\"], start=1):\n",
    "                rating = resume.get(key)  # Use .get() to avoid KeyError\n",
    "                if rating is not None:  # Insert only if the annotation exists\n",
    "                    cursor.execute(\n",
    "                        \"INSERT INTO annotations (resume_id, annotator_id, rating) VALUES (?, ?, ?)\",\n",
    "                        (resume_id, annotator_id, rating),\n",
    "                    )\n",
    "\n",
    "            # Insert naive algorithm predictions\n",
    "            for key, algo in zip([\"naive_alg1_jobs\", \"naive_alg2_jobs\"], [\"naive_alg1\", \"naive_alg2\"]):\n",
    "                for job in resume.get(key, []):  # Use .get() to avoid KeyError\n",
    "                    cursor.execute(\n",
    "                        \"INSERT INTO naive_algorithm_predictions (resume_id, algorithm_version, job_title, similarity_score) VALUES (?, ?, ?, ?)\",\n",
    "                        (resume_id, algo, job[0], job[1]),\n",
    "                    )\n",
    "\n",
    "        print(f\"âœ… Processed: {os.path.basename(json_file)}\")  # Show progress\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error processing {json_file}: {e}\")\n",
    "\n",
    "# Scan directory and process only JSON files\n",
    "json_files = [f for f in os.listdir(scenario_1_dir) if f.endswith(\".json\")]\n",
    "\n",
    "if not json_files:\n",
    "    print(\"âš ï¸ No JSON files found in the directory!\")\n",
    "else:\n",
    "    print(f\"ðŸ“‚ Found {len(json_files)} JSON files. Processing...\")\n",
    "    for json_file in json_files:\n",
    "        insert_annotations(os.path.join(scenario_1_dir, json_file))\n",
    "\n",
    "# Commit and close\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(\"ðŸŽ‰ Scenario 1 data inserted successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
